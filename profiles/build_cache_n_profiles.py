from collections import defaultdict
import json
import logging
import os
from typing import Dict, List
from pathlib import Path

from tqdm import tqdm
# SupplierMetrics and SupplierProfile might be needed if we reconstruct profiles here,
# but the current script only caches raw data.
# from supplier_profiler import SupplierMetrics, SupplierProfile
# from tender_analysis_system import TenderAnalysisSystem # Replaced by system_provider
from system_provider import get_system, is_system_initialized

import pickle

# Configure logging for this module
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class ProfileBuilder:    
    def __init__(self, system): # system is an instance of TenderAnalysisSystem
        self.system = system
        if not self.system or not self.system.is_initialized:
            # This check should ideally be done before creating ProfileBuilder
            logger.error("ProfileBuilder: TenderAnalysisSystem is not initialized!")
            raise ValueError("TenderAnalysisSystem must be initialized before creating ProfileBuilder.")
        self.vector_db = system.vector_db
        # self.profiler = system.supplier_profiler # Not directly used in build_and_cache
        self.logger = logger # Use the module-level logger

    def build_and_cache_supplier_data(self, cache_file_path: str = "files/all_data_cache.pkl", force_rebuild: bool = False):
        """
        Loads all tender data from the vector database, groups it by supplier EDRPOU,
        and saves it to a pickle cache file.
        This cache is intended for use by MarketStatistics and potentially other components
        that need quick access to all historical data without repeated DB queries.
        """
        self.logger.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø—Ä–æ—Ü–µ—Å—É —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è/–æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–µ—à—É –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤.")

        cache_path = Path(cache_file_path)
        cache_path.parent.mkdir(parents=True, exist_ok=True) # Ensure 'files' directory exists

        if not force_rebuild and cache_path.exists():
            self.logger.info(f"üì¶ –ó–Ω–∞–π–¥–µ–Ω–æ —ñ—Å–Ω—É—é—á–∏–π –∫–µ—à –¥–∞–Ω–∏—Ö: {cache_file_path}. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ –ë–î –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
            self.logger.info("üí° –©–æ–± –ø—Ä–∏–º—É—Å–æ–≤–æ –ø–µ—Ä–µ–±—É–¥—É–≤–∞—Ç–∏ –∫–µ—à, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä force_rebuild=True.")
            return True # Indicate cache exists and was not rebuilt

        self.logger.info(f"üî• { '–ü—Ä–∏–º—É—Å–æ–≤–µ –ø–µ—Ä–µ–±—É–¥—É–≤–∞–Ω–Ω—è' if force_rebuild else '–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ' } –∫–µ—à—É –¥–∞–Ω–∏—Ö: {cache_file_path}")

        supplier_data = defaultdict(list)

        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ scroll –∑ vector_db (—è–∫–∏–π —î —á–∞—Å—Ç–∏–Ω–æ—é self.system)
        self.logger.info("‚ö° –ü–æ—á–∞—Ç–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏...")

        if not self.vector_db or not hasattr(self.vector_db, 'client') or not hasattr(self.vector_db, 'collection_name'):
            self.logger.error("‚ùå Vector DB –∫–ª—ñ—î–Ω—Ç –∞–±–æ –Ω–∞–∑–≤–∞ –∫–æ–ª–µ–∫—Ü—ñ—ó –Ω–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω—ñ –≤ TenderAnalysisSystem.")
            return False

        try:
            collection_info = self.vector_db.client.get_collection(
                collection_name=self.vector_db.collection_name
            )
            total_points = collection_info.points_count
            if total_points == 0:
                self.logger.warning(f"‚ö†Ô∏è –í–µ–∫—Ç–æ—Ä–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–∏—Ö '{self.vector_db.collection_name}' –ø–æ—Ä–æ–∂–Ω—è. –ö–µ—à –±—É–¥–µ –ø–æ—Ä–æ–∂–Ω—ñ–º.")
            else:
                self.logger.info(f"üìä –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ –ë–î: {total_points:,}")
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫–æ–ª–µ–∫—Ü—ñ—é '{self.vector_db.collection_name}': {e}")
            self.logger.error("‚ùó –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ –≤–µ–∫—Ç–æ—Ä–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–∏—Ö —ñ—Å–Ω—É—î —Ç–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–µ—Ä–µ–¥ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è–º –∫–µ—à—É.")
            return False

        pbar = tqdm(total=total_points, desc="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –ë–î", unit="–∑–∞–ø–∏—Å—ñ–≤")
        offset = None
        total_loaded_records = 0
        batch_size = 40000  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á—É –¥–ª—è scroll

        while True:
            try:
                records, next_offset = self.vector_db.client.scroll(
                    collection_name=self.vector_db.collection_name,
                    offset=offset,
                    limit=batch_size,
                    with_payload=True,  # –ü–æ—Ç—Ä—ñ–±–Ω—ñ –≤—Å—ñ –¥–∞–Ω—ñ –∑ payload
                    with_vectors=False  # –í–µ–∫—Ç–æ—Ä–∏ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –¥–ª—è —Ü—å–æ–≥–æ –∫–µ—à—É
                )
                if not records:
                    break # –ù–µ–º–∞—î –±—ñ–ª—å—à–µ –∑–∞–ø–∏—Å—ñ–≤

                for record in records:
                    if record.payload:
                        # –í–∞–∂–ª–∏–≤–æ: –∑–∞–±–µ–∑–ø–µ—á–∏—Ç–∏ –æ–¥–Ω–∞–∫–æ–≤—ñ –∫–ª—é—á—ñ, –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ä–µ–≥—ñ—Å—Ç—Ä—É
                        edrpou = record.payload.get('edrpou', record.payload.get('EDRPOU'))
                        if edrpou: # –¢—ñ–ª—å–∫–∏ —è–∫—â–æ —î –Ñ–î–†–ü–û–£
                            supplier_data[str(edrpou)].append(record.payload) # –ö–ª—é—á –∑–∞–≤–∂–¥–∏ —Å—Ç—Ä–æ–∫–∞
                        else:
                            # self.logger.debug(f"–ó–∞–ø–∏—Å –±–µ–∑ –Ñ–î–†–ü–û–£: {record.payload.get('id', 'N/A')}")
                            pass # –ú–æ–∂–Ω–∞ –ª–æ–≥—É–≤–∞—Ç–∏, —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
                    total_loaded_records +=1
                    pbar.update(1)

                if total_loaded_records % (batch_size * 5) == 0: # –õ–æ–≥—É–≤–∞–Ω–Ω—è –∫–æ–∂–Ω—ñ 5 –±–∞—Ç—á—ñ–≤
                    self.logger.info(f"   –ü—Ä–æ–º—ñ–∂–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded_records:,} –∑–∞–ø–∏—Å—ñ–≤, –∑–Ω–∞–π–¥–µ–Ω–æ {len(supplier_data):,} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –Ñ–î–†–ü–û–£...")

                if not next_offset:
                    break # –ö—ñ–Ω–µ—Ü—å –¥–∞–Ω–∏—Ö
                offset = next_offset

            except Exception as e:
                self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ Qdrant: {e}")
                self.logger.error("‚ùó –ú–æ–∂–ª–∏–≤–æ, –ø—Ä–æ–±–ª–µ–º–∞ –∑ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è–º –∞–±–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é –¥–∞–Ω–∏—Ö.")
                pbar.close()
                return False # –ù–µ–≤–¥–∞—á–∞
        pbar.close()

        self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded_records:,} –∑–∞–ø–∏—Å—ñ–≤.")
        self.logger.info(f"üë• –ó–≥—Ä—É–ø–æ–≤–∞–Ω–æ –¥–∞–Ω—ñ –¥–ª—è {len(supplier_data):,} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤.")

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –¥–∞–Ω–∏—Ö
        self.logger.info(f"üíæ –ó–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –∞–≥—Ä–µ–≥–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É –∫–µ—à-—Ñ–∞–π–ª: {cache_file_path}...")
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(dict(supplier_data), f, protocol=pickle.HIGHEST_PROTOCOL)
            self.logger.info(f"‚úÖ –ö–µ—à –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ —É—Å–ø—ñ—à–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {cache_file_path}")
            return True # –£—Å–ø—ñ—Ö
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ –∫–µ—à-—Ñ–∞–π–ª: {e}")
            return False # –ù–µ–≤–¥–∞—á–∞

def run_build_cache(categories_file: str = "data/categories.jsonl",
                    qdrant_host: str = "localhost",
                    qdrant_port: int = 6333,
                    cache_file: str = "files/all_data_cache.pkl",
                    force_rebuild_cache: bool = False):
    """
    –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–ø—É—Å–∫—É –ø—Ä–æ—Ü–µ—Å—É –ø–æ–±—É–¥–æ–≤–∏ –∫–µ—à—É.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î system_provider –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏.
    """
    logger.info("üõ†Ô∏è  –ó–∞–ø—É—Å–∫ –ø–æ–±—É–¥–æ–≤–∏ –∫–µ—à—É –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤...")
    try:
        system = get_system(
            categories_file=categories_file,
            qdrant_host=qdrant_host,
            qdrant_port=qdrant_port
        )
    except Exception as e:
        logger.exception(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ—Ç—Ä–∏–º–∞–Ω–Ω—è/—ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó TenderAnalysisSystem: {e}")
        return

    if not is_system_initialized() or not system.is_initialized:
        logger.error("‚ùå TenderAnalysisSystem –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –Ω–∞–ª–µ–∂–Ω–∏–º —á–∏–Ω–æ–º. –ü–æ–±—É–¥–æ–≤–∞ –∫–µ—à—É –Ω–µ–º–æ–∂–ª–∏–≤–∞.")
        return

    logger.info("‚úÖ TenderAnalysisSystem —É—Å–ø—ñ—à–Ω–æ –æ—Ç—Ä–∏–º–∞–Ω–æ/—ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ.")

    builder = ProfileBuilder(system)
    success = builder.build_and_cache_supplier_data(cache_file_path=cache_file, force_rebuild=force_rebuild_cache)

    if success:
        logger.info("üéâ –ü–æ–±—É–¥–æ–≤–∞ –∫–µ—à—É –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ.")
    else:
        logger.error("üî• –ü–æ–±—É–¥–æ–≤–∞ –∫–µ—à—É –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏ –∞–±–æ –±—É–ª–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")


if __name__ == "__main__":
    # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –¥–ª—è –∑–∞–ø—É—Å–∫—É —è–∫ —Å–∫—Ä–∏–ø—Ç
    DEFAULT_CATEGORIES_FILE = "data/categories.jsonl" # –®–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    DEFAULT_QDRANT_HOST = "localhost"
    DEFAULT_QDRANT_PORT = 6333
    DEFAULT_CACHE_FILE = "files/all_data_cache.pkl"   # –î–µ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ –∫–µ—à
    FORCE_REBUILD = False # –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å True, —â–æ–± –ø—Ä–∏–º—É—Å–æ–≤–æ –ø–µ—Ä–µ–±—É–¥—É–≤–∞—Ç–∏ –∫–µ—à, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤—ñ–Ω —ñ—Å–Ω—É—î

    # –ü—Ä–∏–∫–ª–∞–¥ –∞—Ä–≥—É–º–µ–Ω—Ç—ñ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞ (–º–æ–∂–Ω–∞ —Ä–æ–∑—à–∏—Ä–∏—Ç–∏ argparse)
    import sys
    if len(sys.argv) > 1 and sys.argv[1].lower() == '--force-rebuild':
        logger.info("‚ö° –ü—Ä–∏–º—É—Å–æ–≤–µ –ø–µ—Ä–µ–±—É–¥—É–≤–∞–Ω–Ω—è –∫–µ—à—É –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞.")
        FORCE_REBUILD = True

    run_build_cache(
        categories_file=DEFAULT_CATEGORIES_FILE,
        qdrant_host=DEFAULT_QDRANT_HOST,
        qdrant_port=DEFAULT_QDRANT_PORT,
        cache_file=DEFAULT_CACHE_FILE,
        force_rebuild_cache=FORCE_REBUILD
    )