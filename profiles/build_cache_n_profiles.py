from collections import defaultdict
import json
import logging
import os
from typing import Dict, List

from tqdm import tqdm
from supplier_profiler import SupplierMetrics, SupplierProfile
from tender_analysis_system import TenderAnalysisSystem

import pickle

class ProfileBuilder:    
    def __init__(self, system: TenderAnalysisSystem):
        self.system = system
        self.vector_db = system.vector_db
        self.profiler = system.supplier_profiler
        self.logger = logging.getLogger(__name__)

    def build_and_cache(self):
        self.logger.info("üö® –†–ï–ñ–ò–ú –ü–Ü–î–ì–û–¢–û–í–ö–ò –¢–ê –ö–ï–®–£–í–ê–ù–ù–Ø –î–ê–ù–ò–•")
        cache_file = "files/all_data_cache.pkl"
        supplier_data = defaultdict(list)
        if os.path.exists(cache_file):
            self.logger.info("üì¶ –ó–Ω–∞–π–¥–µ–Ω–æ –∫–µ—à –¥–∞–Ω–∏—Ö, –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
            return
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ scroll
        self.logger.info("‚ö° –ü–æ—á–∞—Ç–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è...")
        collection_info = self.vector_db.client.get_collection(
            collection_name=self.vector_db.collection_name
        )
        total_points = collection_info.points_count
        self.logger.info(f"üìä –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –≤ –ë–î: {total_points:,}")
        pbar = tqdm(total=total_points, desc="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö", unit="–∑–∞–ø–∏—Å—ñ–≤")
        offset = None
        total_loaded = 0
        batch_size = 40000
        while True:
            try:
                records, next_offset = self.vector_db.client.scroll(
                    collection_name=self.vector_db.collection_name,
                    offset=offset,
                    limit=batch_size,
                    with_payload=True,
                    with_vectors=False
                )
                if not records:
                    break
                for record in records:
                    if record.payload:
                        edrpou = (record.payload.get('edrpou') or 
                                  record.payload.get('EDRPOU') or 
                                  '')
                        if edrpou:
                            supplier_data[edrpou].append(record.payload)
                            total_loaded += 1
                            pbar.update(1)
                        else:
                            self.logger.debug(f"–ó–∞–ø–∏—Å –±–µ–∑ –Ñ–î–†–ü–û–£: {record.payload}")
                if total_loaded % 50000 == 0:
                    self.logger.info(f"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded:,} –∑–∞–ø–∏—Å—ñ–≤, —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –Ñ–î–†–ü–û–£: {len(supplier_data):,}")
                if not next_offset:
                    break
                offset = next_offset
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
                break
        pbar.close()
        self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded:,} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è {len(supplier_data):,} –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤")
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –¥–∞–Ω–∏—Ö
        self.logger.info("üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –¥–∞–Ω–∏—Ö...")
        with open(cache_file, 'wb') as f:
            pickle.dump(dict(supplier_data), f)
        self.logger.info(f"‚úÖ –ö–µ—à –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {cache_file}")
if __name__ == "__main__":
    system = TenderAnalysisSystem(
        categories_file="data/categories.jsonl",
        qdrant_host="localhost",
        qdrant_port=6333
    )
    builder = ProfileBuilder(system)
    builder.build_and_cache()