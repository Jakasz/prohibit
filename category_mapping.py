import json
import re
from collections import defaultdict
from difflib import SequenceMatcher
import pandas as pd
from pathlib import Path

def analyze_categories_and_create_mapping(categories_file: str, output_file: str = "category_mappings.json"):
    """
    –ê–Ω–∞–ª—ñ–∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ JSONL —Ñ–∞–π–ª—É —Ç–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–∞–ø–ø—ñ–Ω–≥—É
    """
    print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ {categories_file}...")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    categories = []
    with open(categories_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                if data.get('active', True):  # –¢—ñ–ª—å–∫–∏ –∞–∫—Ç–∏–≤–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
                    categories.append(data.get('category', '').strip())
            except:
                continue
    
    print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(categories)} –∞–∫—Ç–∏–≤–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π")
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–∞ –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è —Å—Ö–æ–∂–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    def normalize_text(text):
        """–ë–∞–∑–æ–≤–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ç–µ–∫—Å—Ç—É"""
        text = text.lower().strip()
        # –í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–π–≤–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
        text = re.sub(r'[^\w\s\-]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≥—Ä—É–ø —Å—Ö–æ–∂–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
    category_groups = defaultdict(list)
    processed = set()
    
    print("üîÑ –ì—Ä—É–ø—É–≤–∞–Ω–Ω—è —Å—Ö–æ–∂–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π...")
    
    for i, cat1 in enumerate(categories):
        if cat1 in processed:
            continue
            
        norm_cat1 = normalize_text(cat1)
        group = [cat1]
        processed.add(cat1)
        
        # –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
        for cat2 in categories[i+1:]:
            if cat2 in processed:
                continue
                
            norm_cat2 = normalize_text(cat2)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ö–æ–∂–æ—Å—Ç—ñ
            similarity = SequenceMatcher(None, norm_cat1, norm_cat2).ratio()
            
            # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Å—Ö–æ–∂–æ—Å—Ç—ñ
            # 1. –û–¥–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è —î –ø—ñ–¥—Å—Ç—Ä–æ–∫–æ—é —ñ–Ω—à–æ—ó
            if (norm_cat1 in norm_cat2 or norm_cat2 in norm_cat1) and len(norm_cat1) > 5:
                group.append(cat2)
                processed.add(cat2)
            # 2. –í–∏—Å–æ–∫–∞ —Å—Ö–æ–∂—ñ—Å—Ç—å (>80%)
            elif similarity > 0.8:
                group.append(cat2)
                processed.add(cat2)
            # 3. –°–ø—ñ–ª—å–Ω—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
            elif len(set(norm_cat1.split()) & set(norm_cat2.split())) >= 2:
                group.append(cat2)
                processed.add(cat2)
        
        # –í–∏–±—ñ—Ä –∫–∞–Ω–æ–Ω—ñ—á–Ω–æ–≥–æ —ñ–º–µ–Ω—ñ (–Ω–∞–π–∫–æ—Ä–æ—Ç—à–µ –∞–±–æ –Ω–∞–π—á–∞—Å—Ç—ñ—à–µ)
        canonical = min(group, key=len)  # –ë–µ—Ä–µ–º–æ –Ω–∞–π–∫–æ—Ä–æ—Ç—à–µ
        category_groups[canonical] = group
    
    print(f"‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ {len(category_groups)} –≥—Ä—É–ø –∫–∞—Ç–µ–≥–æ—Ä—ñ–π")
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –º–∞–ø–ø—ñ–Ω–≥—É
    mapping = {}
    
    # –î–æ–¥–∞—î–º–æ –±–∞–∑–æ–≤—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –∑ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
    base_mappings = {
        "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ñ –ø–æ—Å–ª—É–≥–∏": ["—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç", "–ø–µ—Ä–µ–≤–µ–∑–µ–Ω–Ω—è", "–ª–æ–≥—ñ—Å—Ç–∏–∫–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–≤–∞–Ω—Ç–∞–∂"],
        "–Ü–¢ –ø–æ—Å–ª—É–≥–∏": ["–ø—Ä–æ–≥—Ä–∞–º", "software", "it", "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π", "–∫–æ–º–ø'—é—Ç–µ—Ä", "—Ü–∏—Ñ—Ä–æ–≤"],
        "–ë—É–¥—ñ–≤–µ–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏": ["–±—É–¥—ñ–≤", "–∫–æ–Ω—Å—Ç—Ä—É", "—Ü–µ–º–µ–Ω—Ç", "–±–µ—Ç–æ–Ω", "—Ü–µ–≥–ª–∞"],
        "–ú–µ–¥–∏—á–Ω—ñ —Ç–æ–≤–∞—Ä–∏": ["–º–µ–¥–∏—á", "–ª—ñ–∫–∞—Ä", "—Ñ–∞—Ä–º–∞", "–ø—Ä–µ–ø–∞—Ä–∞—Ç", "–∑–¥–æ—Ä–æ–≤"],
        "–ü—Ä–æ–¥—É–∫—Ç–∏ —Ö–∞—Ä—á—É–≤–∞–Ω–Ω—è": ["–ø—Ä–æ–¥—É–∫—Ç", "—Ö–∞—Ä—á", "—ó–∂–∞", "food", "–º–æ–ª–æ—á", "–º'—è—Å"],
        "–û—Ñ—ñ—Å–Ω—ñ —Ç–æ–≤–∞—Ä–∏": ["–æ—Ñ—ñ—Å", "–∫–∞–Ω—Ü–µ–ª", "–ø–∞–ø—ñ—Ä", "—Ä—É—á–∫", "office"],
        "–ü–∞–ª–∏–≤–æ": ["–ø–∞–ª–∏–≤", "–±–µ–Ω–∑–∏–Ω", "–¥–∏–∑–µ–ª—å", "–≥–∞–∑", "–Ω–∞—Ñ—Ç"],
        "–ó–∞–ø—á–∞—Å—Ç–∏–Ω–∏": ["–∑–∞–ø—á–∞—Å—Ç", "–¥–µ—Ç–∞–ª—å", "–≤—Ç—É–ª–∫", "–ø—ñ–¥—à–∏–ø–Ω–∏–∫", "—Ä–µ–º–æ–Ω—Ç"],
        "–ü–æ—Å–ª—É–≥–∏": ["–ø–æ—Å–ª—É–≥", "—Å–µ—Ä–≤—ñ—Å", "–æ–±—Å–ª—É–≥", "–∫–æ–Ω—Å—É–ª—å—Ç", "service"]
    }
    
    # –†–æ–∑–ø–æ–¥—ñ–ª –≥—Ä—É–ø –ø–æ –±–∞–∑–æ–≤–∏–º –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º
    for canonical, group in category_groups.items():
        matched = False
        norm_canonical = normalize_text(canonical)
        
        # –ü–æ—à—É–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –±–∞–∑–æ–≤–∏–º –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º
        for base_cat, keywords in base_mappings.items():
            for keyword in keywords:
                if keyword in norm_canonical:
                    if base_cat not in mapping:
                        mapping[base_cat] = []
                    mapping[base_cat].extend(group)
                    matched = True
                    break
            if matched:
                break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å - —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—É –∫–∞—Ç–µ–≥–æ—Ä—ñ—é
        if not matched:
            mapping[canonical] = group
    
    # –í–∏–¥–∞–ª–µ–Ω–Ω—è –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤
    for key in mapping:
        mapping[key] = list(set(mapping[key]))
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–∞–ø–ø—ñ–Ω–≥—É:")
    sorted_mapping = sorted(mapping.items(), key=lambda x: len(x[1]), reverse=True)
    for canonical, variants in sorted_mapping[:10]:
        print(f"  {canonical}: {len(variants)} –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤")
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ú–∞–ø–ø—ñ–Ω–≥ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ {output_file}")
    print(f"üìà –í—Å—å–æ–≥–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ–π: {len(mapping)}")
    print(f"üìà –í—Å—å–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤: {sum(len(v) for v in mapping.values())}")
    
    return mapping

# –í–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó
if __name__ == "__main__":
    mapping = analyze_categories_and_create_mapping("categories.jsonl")