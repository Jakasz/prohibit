import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Set
import logging
from pathlib import Path
from collections import defaultdict, Counter
import pickle
import warnings
warnings.filterwarnings('ignore')

# ML —Ç–∞ NLP –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
import joblib

# Qdrant –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
from qdrant_client import QdrantClient
from qdrant_client.http import models
from feature_extractor import FeatureExtractor

class TenderAnalysisSystem:
    """
    –ì–æ–ª–æ–≤–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ç–µ–Ω–¥–µ—Ä—ñ–≤
    
    –ö–æ–æ—Ä–¥–∏–Ω—É—î —Ä–æ–±–æ—Ç—É –≤—Å—ñ—Ö –ø—ñ–¥—Å–∏—Å—Ç–µ–º:
    - –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü—ñ—é —Ç–∞ –∞–Ω–∞–ª—ñ–∑
    - –í–µ–∫—Ç–æ—Ä–Ω—É –±–∞–∑—É –¥–∞–Ω–∏—Ö
    - –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
    - –ê–Ω–∞–ª—ñ—Ç–∏–∫—É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—ó
    """
    
    def __init__(self, 
                 model_path: str = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
                 categories_file: Optional[str] = None,
                 qdrant_host: str = "localhost", 
                 qdrant_port: int = 6333):
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –æ—Å–Ω–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
        self.logger.info("üöÄ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è TenderAnalysisSystem...")
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤
        self.embedding_model = SentenceTransformer(model_path)
        self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –º–æ–¥–µ–ª—å –µ–º–±–µ–¥–∏–Ω–≥—ñ–≤: {model_path}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
        self.categories_manager = None  # –ë—É–¥–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –ø—ñ–∑–Ω—ñ—à–µ
        self.categories_file = categories_file
        
        # –ü—ñ–¥—Å–∏—Å—Ç–µ–º–∏ (–±—É–¥—É—Ç—å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø—ñ–∑–Ω—ñ—à–µ)
        self.vector_db = None
        self.predictor = None
        self.competition_analyzer = None
        self.supplier_profiler = None
        self.feature_extractor = None
        
        # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è Qdrant
        self.qdrant_config = {
            'host': qdrant_host,
            'port': qdrant_port
        }
        
        # –°—Ç–∞–Ω —Å–∏—Å—Ç–µ–º–∏
        self.is_initialized = False
        self.is_trained = False
        self.last_update = None
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —Å–∏—Å—Ç–µ–º–∏
        self.system_metrics = {
            'total_tenders': 0,
            'total_suppliers': 0,
            'total_categories': 0,
            'model_performance': {},
            'last_training_date': None,
            'vector_db_size': 0
        }

    def prepare_training_data(self) -> bool:
        """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
        historical_data = self.vector_db.export_collection_data(limit=100000)
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ—Ñ—ñ–ª—ñ–≤ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
        if hasattr(self.supplier_profiler, 'profiles') and self.supplier_profiler.profiles:
            supplier_profiles = self.supplier_profiler.profiles
        else:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ —Ñ–∞–π–ª—É —è–∫—â–æ —î
            profiles_file = "supplier_profiles_COMPLETE.json"
            if Path(profiles_file).exists():
                self.supplier_profiler.load_profiles(profiles_file)
                supplier_profiles = self.supplier_profiler.profiles
            else:
                self.logger.error("–ü—Ä–æ—Ñ—ñ–ª—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
                return False
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è predictor
        X, y = self.predictor.prepare_training_data_from_history(
            [item['payload'] for item in historical_data if 'payload' in item],
            supplier_profiles
        )
        
        self.predictor.training_data = (X, y)
        return True

    def initialize_system(self) -> bool:
        """
        –ü–æ–≤–Ω–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—Å—ñ—Ö –ø—ñ–¥—Å–∏—Å—Ç–µ–º
        """
        try:
            self.logger.info("üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—ñ–¥—Å–∏—Å—Ç–µ–º...")
            
            # 1. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
            from category_manager import CategoryManager
            self.categories_manager = CategoryManager(self.categories_file)
            
            if Path("category_mappings.json").exists():            
                self.categories_manager.load_category_mappings("category_mappings.json")
                self.logger.info("‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –º–∞–ø–ø—ñ–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π")

            # 2. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
            from vector_database import TenderVectorDB
            self.vector_db = TenderVectorDB(
                embedding_model=self.embedding_model,
                qdrant_host=self.qdrant_config['host'],
                qdrant_port=self.qdrant_config['port']
            )
            
            # 3. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–∏–Ω–∫–æ–≤–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            from market_statistics import MarketStatistics
            self.market_stats = MarketStatistics(
                category_manager=self.categories_manager
            )
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞–±–æ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if not self.market_stats.load_statistics():
                self.logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–∞ –ø—Ä–∏ –ø–µ—Ä—à–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ.")
            
            # 4. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
            from supplier_profiler import SupplierProfiler
            self.supplier_profiler = SupplierProfiler(
                categories_manager=self.categories_manager,
                vector_db=self.vector_db
            )
            
            # 5. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—ó
            from competition_analyzer import CompetitionAnalyzer
            self.competition_analyzer = CompetitionAnalyzer(
                categories_manager=self.categories_manager,
                vector_db=self.vector_db
            )
            
            # 6. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏—Å—Ç–µ–º–∏ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            from prediction_engine import PredictionEngine
            self.predictor = PredictionEngine(
                supplier_profiler=self.supplier_profiler,
                competition_analyzer=self.competition_analyzer,
                categories_manager=self.categories_manager
            )
            
            # 7. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ –æ–∑–Ω–∞–∫
            self.feature_extractor = FeatureExtractor(
                categories_manager=self.categories_manager,
                competition_analyzer=self.competition_analyzer
            )
            
            # –ü–µ—Ä–µ–¥–∞—î–º–æ market_stats –≤ feature_extractor
            self.feature_extractor.set_market_statistics(self.market_stats)
            
            # –ü–µ—Ä–µ–¥–∞—î–º–æ feature_extractor –≤ predictor
            self.predictor.feature_extractor = self.feature_extractor
            
            self.is_initialized = True
            self.logger.info("‚úÖ –í—Å—ñ –ø—ñ–¥—Å–∏—Å—Ç–µ–º–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
            
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó: {e}")
            return False
        

    def update_market_statistics(self) -> Dict[str, Any]:
        """–û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ä–∏–Ω–∫–æ–≤–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö"""
        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        self.logger.info("üìä –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ä–∏–Ω–∫–æ–≤–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ—Å—Ç–æ—Ä–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        historical_data = []
        offset = None
        
        while True:
            try:
                records, next_offset = self.vector_db.client.scroll(
                    collection_name=self.vector_db.collection_name,
                    offset=offset,
                    limit=40000,
                    with_payload=True,
                    with_vectors=False
                )
                
                if not records:
                    break
                    
                for record in records:
                    if record.payload:
                        historical_data.append(record.payload)
                
                if not next_offset:
                    break
                offset = next_offset
                
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
                break
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        results = self.market_stats.calculate_market_statistics(historical_data)
        
        self.logger.info(f"‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è {results['categories_processed']} –∫–∞—Ç–µ–≥–æ—Ä—ñ–π")
        
        return results



    
    def prepare_training_data_from_vector_db(self) -> Tuple[pd.DataFrame, pd.Series]:
        """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏"""
        self.logger.info("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è...")
        
        # 1. –û—Ç—Ä–∏–º—É—î–º–æ –í–°–Ü –∑–∞–ø–∏—Å–∏ –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
        all_records = []
        offset = None
        batch_size = 30000
        
        while True:
            try:
                records, next_offset = self.vector_db.client.scroll(
                    collection_name=self.vector_db.collection_name,
                    offset=offset,
                    limit=batch_size,
                    with_payload=True,
                    with_vectors=False  # –í–µ–∫—Ç–æ—Ä–∏ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
                )
                
                if not records:
                    break
                    
                # –î–æ–¥–∞—î–º–æ payload –∫–æ–∂–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É
                for record in records:
                    if record.payload:
                        all_records.append(record.payload)
                
                if not next_offset:
                    break
                offset = next_offset
                
                self.logger.info(f"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(all_records):,} –∑–∞–ø–∏—Å—ñ–≤...")
                
            except Exception as e:
                self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
                break
        
        self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(all_records):,} –∑–∞–ø–∏—Å—ñ–≤ –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏")
        
        # 2. –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –≤ DataFrame –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ
        df = pd.DataFrame(all_records)
        
        # 3. –í–∏—Ç—è–≥—É—î–º–æ –æ–∑–Ω–∞–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É
        features_list = []
        targets = []
        
        for idx, row in df.iterrows():
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä—è–¥–æ–∫ DataFrame –Ω–∞–∑–∞–¥ —É —Å–ª–æ–≤–Ω–∏–∫
            item = row.to_dict()
            
            # –í–∏—Ç—è–≥—É—î–º–æ –Ñ–î–†–ü–û–£ –¥–ª—è –ø–æ—à—É–∫—É –ø—Ä–æ—Ñ—ñ–ª—é
            edrpou = item.get('edrpou', '')
            
            # –û—Ç—Ä–∏–º—É—î–º–æ –ø—Ä–æ—Ñ—ñ–ª—å –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (—è–∫—â–æ —î)
            supplier_profile = None
            if edrpou and hasattr(self.supplier_profiler, 'profiles'):
                supplier_profile = self.supplier_profiler.profiles.get(edrpou)
                if supplier_profile:
                    supplier_profile = supplier_profile.to_dict()
            
            # –í–∏—Ç—è–≥—É—î–º–æ –≤—Å—ñ –æ–∑–Ω–∞–∫–∏
            features = self.feature_extractor.extract_features(item, supplier_profile)
            features_list.append(features)
            
            # –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ - —á–∏ –≤–∏–≥—Ä–∞–≤ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫
            targets.append(int(item.get('won', False)))
        
        # 4. –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö
        X = pd.DataFrame(features_list)
        y = pd.Series(targets)
        
        # 5. –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–∏—Ö
        self.logger.info(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≤—á–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö:")
        self.logger.info(f"   ‚Ä¢ –í—Å—å–æ–≥–æ –∑—Ä–∞–∑–∫—ñ–≤: {len(X):,}")
        self.logger.info(f"   ‚Ä¢ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {len(X.columns)}")
        self.logger.info(f"   ‚Ä¢ –†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤:")
        self.logger.info(f"     - WON=0 (–ø—Ä–æ–≥—Ä–∞–ª–∏): {(y == 0).sum():,} ({(y == 0).sum() / len(y) * 100:.1f}%)")
        self.logger.info(f"     - WON=1 (–≤–∏–≥—Ä–∞–ª–∏): {(y == 1).sum():,} ({(y == 1).sum() / len(y) * 100:.1f}%)")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å—É –∫–ª–∞—Å—ñ–≤
        if (y == 1).sum() < len(y) * 0.05:
            self.logger.warning("‚ö†Ô∏è –î—É–∂–µ –º–∞–ª–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ (<5%). –ú–æ–¥–µ–ª—å –º–æ–∂–µ –ø–æ–≥–∞–Ω–æ –Ω–∞–≤—á–∞—Ç–∏—Å—è!")
        
        return X, y


   
    def train_prediction_model(self, validation_split: float = 0.2, cv_folds: int = 5) -> Dict[str, Any]:
        """–ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –Ω–∞ –¥–∞–Ω–∏—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏"""
        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        # –û–Ω–æ–≤–ª—é—î–º–æ —Ä–∏–Ω–∫–æ–≤—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–µ—Ä–µ–¥ –Ω–∞–≤—á–∞–Ω–Ω—è–º
        self.logger.info("üìä –û–Ω–æ–≤–ª–µ–Ω–Ω—è —Ä–∏–Ω–∫–æ–≤–æ—ó —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞–≤—á–∞–Ω–Ω—è–º...")
        self.update_market_statistics()

        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        # 1. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö —É –≤–µ–∫—Ç–æ—Ä–Ω—ñ–π –±–∞–∑—ñ
        db_size = self.vector_db.get_collection_size()
        if db_size < 1000:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö —É –≤–µ–∫—Ç–æ—Ä–Ω—ñ–π –±–∞–∑—ñ: {db_size}. –ú—ñ–Ω—ñ–º—É–º 1000 –∑–∞–ø–∏—Å—ñ–≤.")
        
        self.logger.info(f"üéØ –ü–æ—á–∞—Ç–æ–∫ –Ω–∞–≤—á–∞–Ω–Ω—è –Ω–∞ {db_size:,} –∑–∞–ø–∏—Å–∞—Ö –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏...")
        
        try:
            # 2. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
            X, y = self.prepare_training_data_from_vector_db()
            
            # 3. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —É predictor –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
            self.predictor.training_data = (X, y)
            
            # 4. –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
            training_results = self.predictor.train_models(
                X, y,
                test_size=validation_split,
                use_calibration=True
            )
            
            # 5. –û–Ω–æ–≤–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ —Å–∏—Å—Ç–µ–º–∏
            self.system_metrics['model_performance'] = training_results
            self.system_metrics['last_training_date'] = datetime.now().isoformat()
            self.system_metrics['training_samples'] = len(X)
            
            self.is_trained = True
            
            self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ")
            self.logger.info(f"üìà Ensemble AUC: {training_results.get('ensemble', {}).get('test_auc', 0):.4f}")
            
            # 6. –í–∏–≤—ñ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ –∫–æ–∂–Ω—ñ–π –º–æ–¥–µ–ª—ñ
            for model_name, metrics in training_results.items():
                if model_name != 'ensemble' and isinstance(metrics, dict):
                    self.logger.info(f"   ‚Ä¢ {model_name}: AUC = {metrics.get('test_auc', 0):.4f}")
            
            return {
                'performance_metrics': training_results,
                'training_samples': len(X),
                'feature_count': len(X.columns),
                'positive_rate': (y == 1).sum() / len(y)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –Ω–∞–≤—á–∞–Ω–Ω—è: {e}")
            raise

    def predict_tender_outcomes(self, 
                              tender_data: List[Dict],
                              include_competition_analysis: bool = True,
                              include_similar_tenders: bool = True) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Ç–µ–Ω–¥–µ—Ä—ñ–≤
        
        Args:
            tender_data: –î–∞–Ω—ñ —Ç–µ–Ω–¥–µ—Ä—ñ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
            include_competition_analysis: –í–∫–ª—é—á–∏—Ç–∏ –∞–Ω–∞–ª—ñ–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—ó
            include_similar_tenders: –í–∫–ª—é—á–∏—Ç–∏ –ø–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö —Ç–µ–Ω–¥–µ—Ä—ñ–≤
        """
        if not self.is_trained:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞. –í–∏–∫–ª–∏—á—Ç–µ train_prediction_model()")
        
        self.logger.info(f"üîÆ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –¥–ª—è {len(tender_data)} –ø–æ–∑–∏—Ü—ñ–π...")
        
        results = {
            'predictions': {},
            'competition_analysis': {},
            'similar_tenders': {},
            'category_insights': {},
            'processing_time': 0
        }
        
        start_time = datetime.now()
        
        try:
            # 1. –û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–æ–≥–Ω–æ–∑–∏
            predictions = self.predictor.predict_tender(tender_data, supplier_profiles=self.supplier_profiler.profiles)
            results['predictions'] = predictions
            
            # 2. –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—ó (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
            if include_competition_analysis:
                competition_data = {}
                for item in tender_data:
                    tender_num = item.get('F_TENDERNUMBER')
                    if tender_num:
                        competition_data[tender_num] = self.competition_analyzer.analyze_tender_competition(item)
                results['competition_analysis'] = competition_data
            
            # 3. –ü–æ—à—É–∫ —Å—Ö–æ–∂–∏—Ö —Ç–µ–Ω–¥–µ—Ä—ñ–≤ (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
            if include_similar_tenders:
                similar_data = {}
                for item in tender_data:
                    tender_num = item.get('F_TENDERNUMBER')
                    if tender_num:
                        similar_data[tender_num] = self.vector_db.search_similar_tenders(item)
                results['similar_tenders'] = similar_data
            
            # 4. –ê–Ω–∞–ª—ñ–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö
            category_insights = self._analyze_predictions_by_category(tender_data, predictions)
            results['category_insights'] = category_insights
            
            results['processing_time'] = (datetime.now() - start_time).total_seconds()
            
            self.logger.info(f"‚úÖ –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {results['processing_time']:.2f} —Å–µ–∫")
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è: {e}")
            raise
    
    def get_supplier_analytics(self, 
                             edrpou: str,
                             include_competition: bool = True) -> Dict[str, Any]:
        """
        –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–æ–≤–Ω–æ—ó –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏ –ø–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—É
        """
        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        # –ë–∞–∑–æ–≤–∏–π –ø—Ä–æ—Ñ—ñ–ª—å
        profile = self.supplier_profiler.get_supplier_profile(edrpou)
        if not profile:
            return {'error': '–ü–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ'}
        
        result = {
            'profile': profile,
            'competition_metrics': {},
            'category_performance': {},
            'recommendations': []
        }
        
        # –ê–Ω–∞–ª—ñ–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü—ñ—ó
        if include_competition:
            result['competition_metrics'] = self.competition_analyzer.get_supplier_competition_metrics(edrpou)
        
        # –ê–Ω–∞–ª—ñ–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö
        result['category_performance'] = self.categories_manager.get_supplier_category_performance(edrpou)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        result['recommendations'] = self._generate_supplier_recommendations(profile)
        
        return result
    
    def get_category_analytics(self, category_id: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
        """
        if not self.is_initialized:
            raise RuntimeError("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        return {
            'category_info': self.categories_manager.get_category_info(category_id),
            'competition_metrics': self.competition_analyzer.get_category_competition_metrics(category_id),
            'top_suppliers': self.supplier_profiler.get_top_suppliers_in_category(category_id),
            'market_trends': self._analyze_category_trends(category_id)
        }

    def validate_training_readiness(self) -> Tuple[bool, List[str]]:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—ñ –¥–æ –Ω–∞–≤—á–∞–Ω–Ω—è"""
        issues = []
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
        if not self.is_initialized:
            issues.append("–°–∏—Å—Ç–µ–º–∞ –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
        db_size = self.vector_db.get_collection_size()
        if db_size < 1000:
            issues.append(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö —É –≤–µ–∫—Ç–æ—Ä–Ω—ñ–π –±–∞–∑—ñ: {db_size} (–º—ñ–Ω—ñ–º—É–º 1000)")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ—Ñ—ñ–ª—ñ–≤
        if not self.supplier_profiler.profiles:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ –ø—Ä–æ—Ñ—ñ–ª—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π
        if not self.categories_manager.categories:
            issues.append("–ù–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ feature extractor
        if not hasattr(self.predictor, 'feature_extractor'):
            issues.append("Feature extractor –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π")
        
        return len(issues) == 0, issues
    
    
    def update_incremental(self, new_data: List[Dict]) -> Dict[str, Any]:
        """
        –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –Ω–æ–≤–∏–º–∏ –¥–∞–Ω–∏–º–∏
        """
        self.logger.info(f"üîÑ –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∑ {len(new_data)} –∑–∞–ø–∏—Å—ñ–≤...")
        
        # –û–±—Ä–æ–±–∫–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö
        processing_results = self.load_and_process_data(new_data, update_mode=True)
        
        # –ß–∞—Å—Ç–∫–æ–≤–µ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ)
        if len(new_data) > 100:  # –ü–µ—Ä–µ–Ω–∞—á–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –∑–Ω–∞—á–Ω–∏—Ö –æ–Ω–æ–≤–ª–µ–Ω–Ω—è—Ö
            self.logger.info("üìö –ß–∞—Å—Ç–∫–æ–≤–µ –ø–µ—Ä–µ–Ω–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
            training_results = self.train_prediction_model()
            processing_results['model_retrained'] = True
            processing_results['new_performance'] = training_results['performance_metrics']
        else:
            processing_results['model_retrained'] = False
        
        return processing_results
    
    def export_system_state(self) -> Dict[str, Any]:
        """
        –ï–∫—Å–ø–æ—Ä—Ç –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —Å–∏—Å—Ç–µ–º–∏
        """
        return {
            'system_info': {
                'version': '1.0.0',
                'initialized': self.is_initialized,
                'trained': self.is_trained,
                'last_update': self.last_update.isoformat() if self.last_update else None
            },
            'metrics': self.system_metrics,
            'categories_count': len(self.categories_manager.categories) if self.categories_manager else 0,
            'suppliers_count': len(self.supplier_profiler.profiles) if self.supplier_profiler else 0,
            'vector_db_size': self.vector_db.get_collection_size() if self.vector_db else 0
        }
    
    def save_system(self, filepath: str):
        """
        –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–æ–≤–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —Å–∏—Å—Ç–µ–º–∏
        """
        self.logger.info(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –¥–æ {filepath}...")
        
        system_data = {
            'system_state': self.export_system_state(),
            'categories_manager': self.categories_manager.export_state() if self.categories_manager else None,
            'supplier_profiler': self.supplier_profiler.export_state() if self.supplier_profiler else None,
            'predictor': self.predictor.export_state() if self.predictor else None,
            'competition_analyzer': self.competition_analyzer.export_state() if self.competition_analyzer else None
        }
        
        joblib.dump(system_data, filepath)
        self.logger.info("‚úÖ –°–∏—Å—Ç–µ–º—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ")
    
    def load_system(self, filepath: str):
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Å—Ç–∞–Ω—É —Å–∏—Å—Ç–µ–º–∏
        """
        self.logger.info(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ –∑ {filepath}...")
        
        system_data = joblib.load(filepath)
        
        # –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è —Å—Ç–∞–Ω—É –ø—ñ–¥—Å–∏—Å—Ç–µ–º
        if system_data.get('categories_manager'):
            self.categories_manager.load_state(system_data['categories_manager'])
        
        if system_data.get('supplier_profiler'):
            self.supplier_profiler.load_state(system_data['supplier_profiler'])
        
        if system_data.get('predictor'):
            self.predictor.load_state(system_data['predictor'])
            
        if system_data.get('competition_analyzer'):
            self.competition_analyzer.load_state(system_data['competition_analyzer'])
        
        # –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å—Ç–∞–Ω—É
        system_state = system_data.get('system_state', {})
        system_info = system_state.get('system_info', {})
        self.is_initialized = system_info.get('initialized', False)
        self.is_trained = system_info.get('trained', False)
        self.system_metrics = system_info.get('metrics', {})
        
        last_update_str = system_info.get('last_update')
        if last_update_str:
            self.last_update = datetime.fromisoformat(last_update_str)
        
        self.logger.info("‚úÖ –°–∏—Å—Ç–µ–º—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")
    

    # –ü—Ä–∏–≤–∞—Ç–Ω—ñ –¥–æ–ø–æ–º—ñ–∂–Ω—ñ –º–µ—Ç–æ–¥–∏
    
    def _update_system_metrics(self, data: List[Dict]):
        """–û–Ω–æ–≤–ª–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        self.system_metrics['total_tenders'] = len(set(item.get('F_TENDERNUMBER') for item in data))
        self.system_metrics['total_suppliers'] = len(set(item.get('EDRPOU') for item in data))
        self.system_metrics['vector_db_size'] = len(data)
    
    def _analyze_predictions_by_category(self, tender_data: List[Dict], predictions: Dict) -> Dict:
        """–ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö"""
        category_stats = defaultdict(lambda: {'count': 0, 'avg_probability': 0, 'probabilities': []})
        
        for item in tender_data:
            tender_num = item.get('F_TENDERNUMBER')
            if tender_num and tender_num in predictions:
                categories = self.categories_manager.categorize_item(item.get('F_ITEMNAME', ''))
                prob = predictions[tender_num]
                
                for category in categories:
                    category_stats[category]['count'] += 1
                    category_stats[category]['probabilities'].append(prob)
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å–µ—Ä–µ–¥–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å
        for category, stats in category_stats.items():
            if stats['probabilities']:
                stats['avg_probability'] = np.mean(stats['probabilities'])
                stats['std_probability'] = np.std(stats['probabilities'])
                del stats['probabilities']  # –í–∏–¥–∞–ª—è—î–º–æ —Å–∏—Ä—ñ –¥–∞–Ω—ñ
        
        return dict(category_stats)
    
    def _generate_supplier_recommendations(self, profile: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞"""
        recommendations = []
        
        win_rate = profile.get('position_win_rate', 0)
        if win_rate < 0.3:
            recommendations.append("–†–æ–∑–≥–ª—è–Ω—É—Ç–∏ —É—á–∞—Å—Ç—å —É –º–µ–Ω—à –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö")
        
        if len(profile.get('item_categories', {})) < 3:
            recommendations.append("–†–æ–∑—à–∏—Ä–∏—Ç–∏ –∞—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç –ø–æ—Å–ª—É–≥/—Ç–æ–≤–∞—Ä—ñ–≤")
        
        if profile.get('recent_performance', 0) < profile.get('position_win_rate', 0):
            recommendations.append("–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ø—Ä–∏—á–∏–Ω–∏ –∑–Ω–∏–∂–µ–Ω–Ω—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ")
        
        return recommendations
    
    def _analyze_category_trends(self, category_id: str) -> Dict:
        """–ê–Ω–∞–ª—ñ–∑ —Ç—Ä–µ–Ω–¥—ñ–≤ —É –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó"""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —Ç—Ä–µ–Ω–¥—ñ–≤
        return {
            'trend': 'stable',
            'growth_rate': 0.0,
            'seasonal_patterns': []
        }