# –ó–£–ü–ò–ù–Ü–¢–¨ –ø–æ—Ç–æ—á–Ω–∏–π –ø—Ä–æ—Ü–µ—Å (Ctrl+C) —ñ –∑–∞–ø—É—Å—Ç—ñ—Ç—å —Ü–µ:

from asyncio.log import logger
from collections import defaultdict
import json
import logging
import os
from typing import Dict, List

from tqdm import tqdm
from supplier_profiler import SupplierMetrics, SupplierProfile
from tender_analysis_system import TenderAnalysisSystem


import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor
import pickle

class UltraFastProfileBuilder:    
    def __init__(self, system: TenderAnalysisSystem):
        self.system = system
        self.vector_db = system.vector_db
        self.profiler = system.supplier_profiler
        self.logger = logging.getLogger(__name__)


    def _save_batch(self, batch: Dict, total_created: int):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ü–û–í–ù–û–ì–û –±–∞—Ç—á—É –ø—Ä–æ—Ñ—ñ–ª—ñ–≤"""
        filename = f"profiles_batch_{total_created}.json"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ü–û–í–ù–Ü –ø—Ä–æ—Ñ—ñ–ª—ñ
        full_batch = {}
        for edrpou, profile in batch.items():
            full_batch[edrpou] = profile.to_dict()
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(full_batch, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–æ –±–∞—Ç—á {filename} –∑ {len(batch)} –ø—Ä–æ—Ñ—ñ–ª—è–º–∏")




    def emergency_load_and_build(self):
        """–ê–í–ê–†–Ü–ô–ù–ò–ô –†–ï–ñ–ò–ú - –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ –ø–æ–±—É–¥–æ–≤–∞ –æ–¥–Ω–æ—á–∞—Å–Ω–æ"""
        self.logger.info("üö® –ê–í–ê–†–Ü–ô–ù–ò–ô –†–ï–ñ–ò–ú –ü–û–ë–£–î–û–í–ò")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ profiler
        if self.profiler is None:
            self.logger.error("‚ùå profiler is None! –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π...")
            from supplier_profiler import SupplierProfiler
            self.profiler = SupplierProfiler()
        
        if not hasattr(self.profiler, 'profiles'):
            self.profiler.profiles = {}
        
        # 1. –°–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–µ—à–æ–≤–∞–Ω–∏–π –¥–∞–º–ø —è–∫—â–æ —î
        cache_file = "all_data_cache.pkl"
        supplier_data = defaultdict(list)
        
        if os.path.exists(cache_file):
            self.logger.info("üì¶ –ó–Ω–∞–π–¥–µ–Ω–æ –∫–µ—à –¥–∞–Ω–∏—Ö, –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ...")
            with open(cache_file, 'rb') as f:
                supplier_data = pickle.load(f)
            self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(supplier_data)} –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ –∑ –∫–µ—à—É")
        else:
            # 2. –ü–†–ê–í–ò–õ–¨–ù–ï –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ scroll
            self.logger.info("‚ö° –ü–æ—á–∞—Ç–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è...")
            
            # –û—Ç—Ä–∏–º–∞—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å
            collection_info = self.vector_db.client.get_collection(
                collection_name=self.vector_db.collection_name
            )
            total_points = collection_info.points_count
            self.logger.info(f"üìä –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –≤ –ë–î: {total_points:,}")
            
            pbar = tqdm(total=total_points, desc="–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö", unit="–∑–∞–ø–∏—Å—ñ–≤")
            
            # –ü–†–ê–í–ò–õ–¨–ù–ò–ô SCROLL
            offset = None
            total_loaded = 0
            batch_size = 10000  # –ë—ñ–ª—å—à–∏–π –±–∞—Ç—á –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            
            while True:
                try:
                    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ scroll –ø—Ä–∞–≤–∏–ª—å–Ω–æ
                    records, next_offset = self.vector_db.client.scroll(
                        collection_name=self.vector_db.collection_name,
                        offset=offset,
                        limit=batch_size,
                        with_payload=True,
                        with_vectors=False
                    )
                    
                    if not records:
                        break
                    
                    # –ì—Ä—É–ø—É—î–º–æ –ø–æ –Ñ–î–†–ü–û–£
                    for record in records:
                        if record.payload:
                            # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä—ñ–∑–Ω—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –ø–æ–ª—ñ–≤
                            edrpou = (record.payload.get('edrpou') or 
                                    record.payload.get('EDRPOU') or 
                                    '')
                            
                            if edrpou:
                                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤–µ—Å—å payload
                                supplier_data[edrpou].append(record.payload)
                                total_loaded += 1
                                pbar.update(1)
                            else:
                                # –õ–æ–≥—É—î–º–æ –ø—Ä–æ–±–ª–µ–º–Ω—ñ –∑–∞–ø–∏—Å–∏
                                self.logger.debug(f"–ó–∞–ø–∏—Å –±–µ–∑ –Ñ–î–†–ü–û–£: {record.payload}")
                    
                    # –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É
                    if total_loaded % 50000 == 0:
                        self.logger.info(f"   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded:,} –∑–∞–ø–∏—Å—ñ–≤, —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –Ñ–î–†–ü–û–£: {len(supplier_data):,}")
                    
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –±–∞—Ç—á—É
                    if not next_offset:
                        break
                    offset = next_offset
                    
                except Exception as e:
                    self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
                    break
            
            pbar.close()
            self.logger.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {total_loaded:,} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è {len(supplier_data):,} –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤")

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –¥–∞–Ω–∏—Ö
            self.logger.info("üíæ –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –¥–∞–Ω–∏—Ö...")
            with open(cache_file, 'wb') as f:
                pickle.dump(dict(supplier_data), f)

        # 3. –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–∞–Ω–∏—Ö
        self.logger.info("\nüîç –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –î–ê–ù–ò–•:")
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø–µ—Ä—à—ñ –∫—ñ–ª—å–∫–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
        for i, (edrpou, items) in enumerate(list(supplier_data.items())[:5]):
            self.logger.info(f"–Ñ–î–†–ü–û–£ {edrpou}: {len(items)} –∑–∞–ø–∏—Å—ñ–≤")
            if items:
                first_item = items[0]
                self.logger.info(f"  –ü—Ä–∏–∫–ª–∞–¥ –ø–æ–ª—ñ–≤: {list(first_item.keys())[:10]}")
                self.logger.info(f"  –ù–∞–∑–≤–∞: {first_item.get('supplier_name') or first_item.get('supp_name') or '–ù–ï –ó–ù–ê–ô–î–ï–ù–û'}")

        # 4. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—ñ–≤
        self.logger.info("üèÅ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—ñ–≤...")
        
        all_profiles = {}
        
        final_pbar = tqdm(supplier_data.items(), desc="–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—ñ–≤")
        profiles_created = 0
        errors = 0
        
        for edrpou, items in final_pbar:
            if len(items) > 0:
                try:
                    # –í–ò–ö–û–†–ò–°–¢–û–í–£–Ñ–ú–û –ú–ï–¢–û–î profiler.create_profile()
                    profile = self.profiler.create_profile(edrpou, items)
                    
                    if profile:
                        all_profiles[edrpou] = profile
                        self.profiler.profiles[edrpou] = profile
                        profiles_created += 1
                    else:
                        self.logger.warning(f"–ü—Ä–æ—Ñ—ñ–ª—å –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –¥–ª—è {edrpou}")
                        
                except Exception as e:
                    errors += 1
                    self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ—Ñ—ñ–ª—é {edrpou}: {e}")
                    import traceback
                    self.logger.error(traceback.format_exc())
                    
            final_pbar.set_postfix({
                'profiles': profiles_created,
                'errors': errors,
                'items': len(items)
            })
        
        # 5. –§–Ü–ù–ê–õ–¨–ù–ï –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –í–°–Ü–• –ü–†–û–§–Ü–õ–Ü–í
        self.logger.info("üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª—É –∑ —É—Å—ñ–º–∞ –ø—Ä–æ—Ñ—ñ–ª—è–º–∏...")
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–±—É–¥–æ–≤–∞–Ω–∏–π –º–µ—Ç–æ–¥ profiler –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        self.profiler.save_profiles("supplier_profiles_COMPLETE.json")
        
        self.logger.info(f"‚úÖ –ì–û–¢–û–í–û! –°—Ç–≤–æ—Ä–µ–Ω–æ {len(all_profiles)} –ø—Ä–æ—Ñ—ñ–ª—ñ–≤")
        self.logger.info(f"‚ùå –ü–æ–º–∏–ª–æ–∫: {errors}")
        self.logger.info(f"üìÅ –§—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª: supplier_profiles_COMPLETE.json")
        
        # 6. –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        self.logger.info("\nüìä –î–Ü–ê–ì–ù–û–°–¢–ò–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í:")
        sorted_suppliers = sorted(supplier_data.items(), key=lambda x: len(x[1]), reverse=True)
        for i, (edrpou, items) in enumerate(sorted_suppliers[:10]):
            profile = all_profiles.get(edrpou)
            if profile:
                self.logger.info(f"   #{i+1} –Ñ–î–†–ü–û–£ {edrpou}: {len(items)} –∑–∞–ø–∏—Å—ñ–≤ –≤ –¥–∞–Ω–∏—Ö, "
                            f"{profile.metrics.total_positions} –ø–æ–∑–∏—Ü—ñ–π –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ, "
                            f"win_rate={profile.metrics.win_rate:.2%}")
        
        return len(all_profiles)
if __name__ == "__main__":
    system = TenderAnalysisSystem(
        categories_file="data/categories.jsonl",
        qdrant_host="localhost", 
        qdrant_port=6333
    )
    system.initialize_system()
    
    # –£–ª—å—Ç—Ä–∞ —à–≤–∏–¥–∫–∏–π –±—ñ–ª–¥–µ—Ä
    builder = UltraFastProfileBuilder(system)
    
    # –ü–û–á–•–ê–õ–ò!
    total = builder.emergency_load_and_build()